{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI Connection Test - System 2\n",
    "\n",
    "This notebook tests Azure OpenAI connectivity using **two credential modes**:\n",
    "\n",
    "1. **AWS Secrets Manager Mode (Default)** - Uses boto3 + config.yaml\n",
    "2. **Environment Variables Mode (Optional)** - Uses .env file\n",
    "\n",
    "---\n",
    "\n",
    "## Configuration\n",
    "\n",
    "Choose your credential mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your credential mode here\n",
    "CREDENTIAL_MODE = \"secrets\"  # Options: \"secrets\" or \"env\"\n",
    "\n",
    "print(f\"Testing with credential mode: {CREDENTIAL_MODE.upper()}\")\n",
    "\n",
    "if CREDENTIAL_MODE == \"secrets\":\n",
    "    print(\"\"\"\n",
    "ðŸ“‹ AWS Secrets Manager Mode:\n",
    "  âœ… Credentials fetched from AWS Secrets Manager via boto3\n",
    "  âœ… Uses config.yaml (cfg.aws['secret_name'], cfg.aws['region_name'])\n",
    "  âœ… Requires: AWS credentials (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\n",
    "  âœ… Requires: boto3 installed\n",
    "    \"\"\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "ðŸ“‹ Environment Variables Mode:\n",
    "  âœ… Credentials from .env file\n",
    "  âœ… Requires: AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_API_KEY\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "project_root = Path.cwd()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… Environment setup complete\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.utils.utils import gai, initialize_client, get_secret, Config\n",
    "\n",
    "print(\"âœ… Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test 1: Configuration Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(f\"TEST 1: Configuration Check ({CREDENTIAL_MODE.upper()} Mode)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if CREDENTIAL_MODE == \"secrets\":\n",
    "    # AWS Secrets Manager mode - check config.yaml and AWS credentials\n",
    "    print(\"\\nMode: AWS Secrets Manager (boto3)\")\n",
    "    print(\"Credentials will be fetched from AWS Secrets Manager, NOT environment variables\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Load config.yaml\n",
    "        cfg = Config.from_yaml('shared/config/config.yaml')\n",
    "        print(f\"âœ… config.yaml loaded\")\n",
    "        \n",
    "        # Check AWS config section\n",
    "        if hasattr(cfg, 'aws'):\n",
    "            print(f\"\\nâœ… AWS configuration found in config.yaml:\")\n",
    "            print(f\"  - secret_name: {cfg.aws.get('secret_name', 'NOT SET')}\")\n",
    "            print(f\"  - region_name: {cfg.aws.get('region_name', 'NOT SET')}\")\n",
    "            print(f\"  - api_version: {cfg.aws.get('api_version', 'NOT SET')}\")\n",
    "        else:\n",
    "            print(f\"\\nâŒ No 'aws' section in config.yaml\")\n",
    "            raise ValueError(\"config.yaml missing 'aws' section\")\n",
    "        \n",
    "        # Check AWS credentials (for boto3)\n",
    "        aws_key = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "        aws_secret = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "        \n",
    "        if aws_key and aws_secret:\n",
    "            print(f\"\\nâœ… AWS credentials found (for boto3):\")\n",
    "            print(f\"  - AWS_ACCESS_KEY_ID: {aws_key[:8]}...{aws_key[-4:]}\")\n",
    "            print(f\"  - AWS_SECRET_ACCESS_KEY: ****\")\n",
    "        else:\n",
    "            print(f\"\\nâŒ AWS credentials not found\")\n",
    "            print(f\"  boto3 needs AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY\")\n",
    "            raise ValueError(\"Missing AWS credentials for boto3\")\n",
    "        \n",
    "        print(f\"\\nâœ… TEST 1 PASSED\")\n",
    "        print(f\"\\nâš ï¸  Note: Azure credentials will be fetched from AWS Secrets Manager when needed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ TEST 1 FAILED\")\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "else:\n",
    "    # Environment variables mode - check AZURE_OPENAI_* env vars\n",
    "    print(\"\\nMode: Environment Variables\")\n",
    "    print(\"Checking for AZURE_OPENAI_* environment variables\\n\")\n",
    "    \n",
    "    required_vars = {\n",
    "        'AZURE_OPENAI_ENDPOINT': os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    "        'AZURE_OPENAI_API_KEY': os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    }\n",
    "    \n",
    "    all_set = True\n",
    "    for var_name, var_value in required_vars.items():\n",
    "        if var_value:\n",
    "            if 'KEY' in var_name:\n",
    "                masked = var_value[:8] + '...' + var_value[-4:] if len(var_value) > 12 else '***'\n",
    "                print(f\"  âœ… {var_name}: {masked}\")\n",
    "            else:\n",
    "                print(f\"  âœ… {var_name}: {var_value}\")\n",
    "        else:\n",
    "            print(f\"  âŒ {var_name}: NOT SET\")\n",
    "            all_set = False\n",
    "    \n",
    "    optional_vars = {\n",
    "        'AZURE_OPENAI_API_VERSION': os.getenv('AZURE_OPENAI_API_VERSION', '2024-02-15-preview'),\n",
    "        'AZURE_OPENAI_DEPLOYMENT': os.getenv('AZURE_OPENAI_DEPLOYMENT', 'gpt-4o-mini'),\n",
    "    }\n",
    "    \n",
    "    print(\"\\nOptional (with defaults):\")\n",
    "    for var_name, var_value in optional_vars.items():\n",
    "        print(f\"  {var_name}: {var_value}\")\n",
    "    \n",
    "    if all_set:\n",
    "        print(f\"\\nâœ… TEST 1 PASSED\")\n",
    "    else:\n",
    "        print(f\"\\nâŒ TEST 1 FAILED: Missing required environment variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test 2: Fetch Secret from AWS Secrets Manager\n",
    "\n",
    "**Only for AWS Secrets Manager mode** - test that we can fetch the secret via boto3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREDENTIAL_MODE == \"secrets\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"TEST 2: Fetch Secret from AWS Secrets Manager\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        print(\"\\nAttempting to fetch secret from AWS Secrets Manager...\")\n",
    "        print(f\"Using boto3 with config from config.yaml\\n\")\n",
    "        \n",
    "        secret_string = get_secret()\n",
    "        credentials = json.loads(secret_string)\n",
    "        \n",
    "        print(f\"âœ… Secret fetched successfully from AWS Secrets Manager\")\n",
    "        print(f\"\\nSecret contains:\")\n",
    "        for key in credentials.keys():\n",
    "            if key.lower() in ['key', 'api_key', 'apikey']:\n",
    "                print(f\"  - {key}: ****\")\n",
    "            elif key.lower() in ['endpoint', 'url']:\n",
    "                print(f\"  - {key}: {credentials[key]}\")\n",
    "            else:\n",
    "                print(f\"  - {key}: {credentials[key]}\")\n",
    "        \n",
    "        # Verify expected fields\n",
    "        if 'endpoint' in credentials and 'key' in credentials:\n",
    "            print(f\"\\nâœ… TEST 2 PASSED: Secret has required fields (endpoint, key)\")\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸  TEST 2 WARNING: Secret missing 'endpoint' or 'key' fields\")\n",
    "            print(f\"  Expected format: {{\\\"endpoint\\\": \\\"...\\\", \\\"key\\\": \\\"...\\\"}}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ TEST 2 FAILED\")\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"\\nðŸ’¡ Troubleshooting:\")\n",
    "        print(f\"  - Verify the secret exists in AWS Secrets Manager\")\n",
    "        print(f\"  - Check secret name matches config.yaml\")\n",
    "        print(f\"  - Ensure IAM permissions allow reading the secret\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"Skipping Test 2 (only for AWS Secrets Manager mode)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test 3: Azure OpenAI Client Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(f\"TEST 3: Client Initialization ({CREDENTIAL_MODE.upper()} Mode)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "use_env_vars = (CREDENTIAL_MODE == \"env\")\n",
    "\n",
    "try:\n",
    "    print(f\"\\nInitializing Azure OpenAI client...\")\n",
    "    if use_env_vars:\n",
    "        print(f\"Credential source: Environment Variables\")\n",
    "    else:\n",
    "        print(f\"Credential source: AWS Secrets Manager (via boto3)\")\n",
    "    \n",
    "    client = initialize_client(use_env_vars=use_env_vars)\n",
    "    \n",
    "    print(f\"\\nâœ… Client initialized successfully\")\n",
    "    print(f\"Client type: {type(client).__name__}\")\n",
    "    print(f\"\\nâœ… TEST 3 PASSED\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ TEST 3 FAILED\")\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test 4: Simple LLM Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(f\"TEST 4: Simple LLM Call ({CREDENTIAL_MODE.upper()} Mode)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "use_env = (CREDENTIAL_MODE == \"env\")\n",
    "\n",
    "try:\n",
    "    print(f\"\\nSending test prompt to Azure OpenAI...\")\n",
    "    \n",
    "    response = gai(\n",
    "        sys_prompt=\"You are a helpful assistant.\",\n",
    "        user_prompt=\"Say 'Hello from Azure OpenAI!' and nothing else.\",\n",
    "        model=\"gpt-4o-mini\",\n",
    "        source=\"azure\",\n",
    "        azure_use_env=use_env\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… LLM call successful!\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(f\"\\nâœ… TEST 4 PASSED\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ TEST 4 FAILED\")\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test 5: JSON Response Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(f\"TEST 5: JSON Response Parsing ({CREDENTIAL_MODE.upper()} Mode)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "use_env = (CREDENTIAL_MODE == \"env\")\n",
    "\n",
    "try:\n",
    "    print(f\"\\nRequesting JSON response...\")\n",
    "    \n",
    "    response = gai(\n",
    "        sys_prompt=\"You are a helpful assistant that responds in JSON format.\",\n",
    "        user_prompt=(\n",
    "            \"Respond with a JSON object with these fields:\\n\"\n",
    "            \"- status: 'success'\\n\"\n",
    "            \"- message: 'Azure OpenAI is working'\\n\"\n",
    "            \"- test_passed: true\\n\"\n",
    "            \"Respond ONLY with the JSON object.\"\n",
    "        ),\n",
    "        model=\"gpt-4o-mini\",\n",
    "        source=\"azure\",\n",
    "        azure_use_env=use_env\n",
    "    )\n",
    "    \n",
    "    if isinstance(response, dict):\n",
    "        print(f\"\\nâœ… JSON parsed successfully:\")\n",
    "        for key, value in response.items():\n",
    "            print(f\"  - {key}: {value}\")\n",
    "        \n",
    "        if response.get('status') == 'success':\n",
    "            print(f\"\\nâœ… TEST 5 PASSED\")\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸  JSON received but validation failed\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  Response not parsed as JSON: {response}\")\n",
    "        print(f\"âŒ TEST 5 FAILED\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ TEST 5 FAILED\")\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test 6: Materiality Scoring Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(f\"TEST 6: Materiality Scoring Format ({CREDENTIAL_MODE.upper()} Mode)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "use_env = (CREDENTIAL_MODE == \"env\")\n",
    "\n",
    "sys_prompt = \"\"\"You are an expert analyst assessing the material impact of soft power events.\n",
    "\n",
    "Assign a materiality score from 1.0 to 10.0.\n",
    "\n",
    "Scoring Scale:\n",
    "- 1-3: Symbolic/rhetorical\n",
    "- 4-6: Mixed symbolic and material\n",
    "- 7-10: Highly material (concrete infrastructure, specific financial commitments)\n",
    "\n",
    "Output JSON format:\n",
    "{\"material_score\": 7.5, \"justification\": \"Brief explanation\"}\n",
    "\n",
    "Respond with ONLY the JSON object.\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"Event: China-Egypt Belt and Road Infrastructure Agreement\n",
    "Country: China | Recipients: Egypt | Date: 2024-08-15\n",
    "\n",
    "Description: China and Egypt signed infrastructure agreement under Belt and Road Initiative, \n",
    "including $2.5 billion financing for high-speed rail and port expansion. Construction starts Q1 2025.\"\"\"\n",
    "\n",
    "try:\n",
    "    print(f\"\\nTesting materiality scoring format...\")\n",
    "    \n",
    "    response = gai(\n",
    "        sys_prompt=sys_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        model=\"gpt-4o-mini\",\n",
    "        source=\"azure\",\n",
    "        azure_use_env=use_env\n",
    "    )\n",
    "    \n",
    "    if isinstance(response, dict):\n",
    "        score = response.get('material_score')\n",
    "        justification = response.get('justification', '')\n",
    "        \n",
    "        print(f\"\\nâœ… Materiality response:\")\n",
    "        print(f\"  - Material Score: {score}/10.0\")\n",
    "        print(f\"  - Justification: {justification[:100]}...\" if len(justification) > 100 else f\"  - Justification: {justification}\")\n",
    "        \n",
    "        if isinstance(score, (int, float)) and 1.0 <= score <= 10.0:\n",
    "            print(f\"\\nâœ… TEST 6 PASSED\")\n",
    "            print(f\"\\nðŸŽ‰ Azure OpenAI setup is ready for the materiality scoring pipeline!\")\n",
    "        else:\n",
    "            print(f\"\\nâŒ Score validation failed (expected 1.0-10.0, got {score})\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  Response not JSON: {response}\")\n",
    "        print(f\"âŒ TEST 6 FAILED\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ TEST 6 FAILED\")\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if CREDENTIAL_MODE == \"secrets\":\n",
    "    print(\"\"\"\n",
    "âœ… AWS Secrets Manager Mode (Production)\n",
    "\n",
    "If all tests passed, you're ready to use:\n",
    "\n",
    "  response = gai(\n",
    "      sys_prompt=\"...\",\n",
    "      user_prompt=\"...\",\n",
    "      source=\"azure\"  # Uses boto3 + AWS Secrets Manager automatically\n",
    "  )\n",
    "\n",
    "What happens:\n",
    "  1. gai() calls initialize_client(use_env_vars=False)\n",
    "  2. initialize_client() calls get_secret()\n",
    "  3. get_secret() reads cfg.aws from config.yaml\n",
    "  4. boto3 fetches secret from AWS Secrets Manager\n",
    "  5. Azure credentials extracted and used\n",
    "\n",
    "No Azure environment variables needed!\n",
    "    \"\"\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "âœ… Environment Variables Mode (Alternative)\n",
    "\n",
    "If all tests passed, you're ready to use:\n",
    "\n",
    "  response = gai(\n",
    "      sys_prompt=\"...\",\n",
    "      user_prompt=\"...\",\n",
    "      source=\"azure\",\n",
    "      azure_use_env=True  # Use env vars instead of AWS Secrets Manager\n",
    "  )\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
