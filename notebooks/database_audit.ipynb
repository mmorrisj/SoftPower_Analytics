{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft Power Database Audit\n",
    "\n",
    "Comprehensive audit of all database tables and metrics, with focus on:\n",
    "- Documents and their distribution\n",
    "- Event hierarchies (clusters, canonical events, daily mentions, summaries)\n",
    "- Country analysis (influencers and recipients from config.yaml)\n",
    "- Embeddings and vector stores\n",
    "- Date coverage and temporal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from datetime import datetime, date\n",
    "from sqlalchemy import text, func\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Database connection\n",
    "from shared.database.database import get_engine, get_session\n",
    "\n",
    "# Load config\n",
    "with open(project_root / 'shared/config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "INFLUENCERS = config.get('influencers', [])\n",
    "RECIPIENTS = config.get('recipients', [])\n",
    "CATEGORIES = config.get('categories', [])\n",
    "\n",
    "print(\"Configuration Loaded\")\n",
    "print(f\"  Influencing Countries: {INFLUENCERS}\")\n",
    "print(f\"  Recipient Countries: {len(RECIPIENTS)} countries\")\n",
    "print(f\"  Categories: {CATEGORIES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run queries\n",
    "def run_query(query, params=None):\n",
    "    \"\"\"Run a SQL query and return results as DataFrame.\"\"\"\n",
    "    engine = get_engine()\n",
    "    with engine.connect() as conn:\n",
    "        result = pd.read_sql(text(query), conn, params=params)\n",
    "    return result\n",
    "\n",
    "def run_scalar(query, params=None):\n",
    "    \"\"\"Run a SQL query and return scalar result.\"\"\"\n",
    "    engine = get_engine()\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(query), params or {}).scalar()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Table Overview\n",
    "\n",
    "Summary of all tables and their row counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all table counts\n",
    "tables_query = \"\"\"\n",
    "SELECT \n",
    "    schemaname,\n",
    "    relname as table_name,\n",
    "    n_live_tup as row_count\n",
    "FROM pg_stat_user_tables\n",
    "ORDER BY n_live_tup DESC\n",
    "\"\"\"\n",
    "\n",
    "tables_df = run_query(tables_query)\n",
    "print(\"=\" * 60)\n",
    "print(\"TABLE OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal tables: {len(tables_df)}\")\n",
    "print(f\"Total rows across all tables: {tables_df['row_count'].sum():,}\")\n",
    "print(\"\\n\")\n",
    "tables_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Documents Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DOCUMENTS TABLE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Basic counts\n",
    "doc_count = run_scalar(\"SELECT COUNT(*) FROM documents\")\n",
    "print(f\"\\nTotal Documents: {doc_count:,}\")\n",
    "\n",
    "# Date range\n",
    "date_range = run_query(\"\"\"\n",
    "    SELECT \n",
    "        MIN(date) as earliest_date,\n",
    "        MAX(date) as latest_date,\n",
    "        COUNT(DISTINCT date) as unique_dates\n",
    "    FROM documents\n",
    "    WHERE date IS NOT NULL\n",
    "\"\"\")\n",
    "print(f\"\\nDate Range:\")\n",
    "print(f\"  Earliest: {date_range['earliest_date'].iloc[0]}\")\n",
    "print(f\"  Latest: {date_range['latest_date'].iloc[0]}\")\n",
    "print(f\"  Unique Dates: {date_range['unique_dates'].iloc[0]:,}\")\n",
    "\n",
    "# Documents by month\n",
    "docs_by_month = run_query(\"\"\"\n",
    "    SELECT \n",
    "        DATE_TRUNC('month', date)::date as month,\n",
    "        COUNT(*) as doc_count\n",
    "    FROM documents\n",
    "    WHERE date IS NOT NULL\n",
    "    GROUP BY DATE_TRUNC('month', date)\n",
    "    ORDER BY month\n",
    "\"\"\")\n",
    "print(f\"\\nDocuments by Month:\")\n",
    "docs_by_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents by initiating country (from config influencers)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DOCUMENTS BY INITIATING COUNTRY (Influencers)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "init_country_query = \"\"\"\n",
    "    SELECT \n",
    "        initiating_country,\n",
    "        COUNT(*) as doc_count,\n",
    "        MIN(date) as earliest_date,\n",
    "        MAX(date) as latest_date\n",
    "    FROM documents\n",
    "    WHERE initiating_country IS NOT NULL\n",
    "    GROUP BY initiating_country\n",
    "    ORDER BY doc_count DESC\n",
    "\"\"\"\n",
    "init_countries = run_query(init_country_query)\n",
    "\n",
    "# Highlight config influencers\n",
    "init_countries['in_config'] = init_countries['initiating_country'].isin(INFLUENCERS)\n",
    "print(\"\\nAll Initiating Countries:\")\n",
    "display(init_countries)\n",
    "\n",
    "# Summary for config influencers\n",
    "config_influencers = init_countries[init_countries['in_config']]\n",
    "print(f\"\\nConfig Influencers Coverage:\")\n",
    "print(f\"  Total docs from config influencers: {config_influencers['doc_count'].sum():,}\")\n",
    "print(f\"  Percentage of total: {config_influencers['doc_count'].sum() / doc_count * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents by recipient country (from config recipients)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DOCUMENTS BY RECIPIENT COUNTRY (Recipients)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rec_country_query = \"\"\"\n",
    "    SELECT \n",
    "        recipient_country,\n",
    "        COUNT(*) as doc_count,\n",
    "        MIN(date) as earliest_date,\n",
    "        MAX(date) as latest_date\n",
    "    FROM documents\n",
    "    WHERE recipient_country IS NOT NULL\n",
    "    GROUP BY recipient_country\n",
    "    ORDER BY doc_count DESC\n",
    "\"\"\"\n",
    "rec_countries = run_query(rec_country_query)\n",
    "\n",
    "# Highlight config recipients\n",
    "rec_countries['in_config'] = rec_countries['recipient_country'].isin(RECIPIENTS)\n",
    "print(\"\\nTop 30 Recipient Countries:\")\n",
    "display(rec_countries.head(30))\n",
    "\n",
    "# Summary for config recipients\n",
    "config_recipients = rec_countries[rec_countries['in_config']]\n",
    "print(f\"\\nConfig Recipients Coverage:\")\n",
    "print(f\"  Total docs to config recipients: {config_recipients['doc_count'].sum():,}\")\n",
    "print(f\"  Percentage of total: {config_recipients['doc_count'].sum() / doc_count * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents by category\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DOCUMENTS BY CATEGORY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "category_query = \"\"\"\n",
    "    SELECT \n",
    "        category,\n",
    "        COUNT(*) as doc_count\n",
    "    FROM documents\n",
    "    WHERE category IS NOT NULL\n",
    "    GROUP BY category\n",
    "    ORDER BY doc_count DESC\n",
    "\"\"\"\n",
    "categories = run_query(category_query)\n",
    "categories['in_config'] = categories['category'].isin(CATEGORIES)\n",
    "print(\"\\nCategories:\")\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salience analysis\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SALIENCE DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "salience_query = \"\"\"\n",
    "    SELECT \n",
    "        salience_bool,\n",
    "        COUNT(*) as doc_count\n",
    "    FROM documents\n",
    "    GROUP BY salience_bool\n",
    "    ORDER BY doc_count DESC\n",
    "\"\"\"\n",
    "salience_dist = run_query(salience_query)\n",
    "print(\"\\nSalience Distribution:\")\n",
    "salience_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Normalized Relationship Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"NORMALIZED RELATIONSHIP TABLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Categories table\n",
    "cat_count = run_scalar(\"SELECT COUNT(*) FROM categories\")\n",
    "cat_unique = run_scalar(\"SELECT COUNT(DISTINCT category) FROM categories\")\n",
    "print(f\"\\nCategories Table:\")\n",
    "print(f\"  Total rows: {cat_count:,}\")\n",
    "print(f\"  Unique categories: {cat_unique}\")\n",
    "\n",
    "# Subcategories table\n",
    "subcat_count = run_scalar(\"SELECT COUNT(*) FROM subcategories\")\n",
    "subcat_unique = run_scalar(\"SELECT COUNT(DISTINCT subcategory) FROM subcategories\")\n",
    "print(f\"\\nSubcategories Table:\")\n",
    "print(f\"  Total rows: {subcat_count:,}\")\n",
    "print(f\"  Unique subcategories: {subcat_unique}\")\n",
    "\n",
    "# Initiating countries table\n",
    "init_count = run_scalar(\"SELECT COUNT(*) FROM initiating_countries\")\n",
    "init_unique = run_scalar(\"SELECT COUNT(DISTINCT initiating_country) FROM initiating_countries\")\n",
    "print(f\"\\nInitiating Countries Table:\")\n",
    "print(f\"  Total rows: {init_count:,}\")\n",
    "print(f\"  Unique countries: {init_unique}\")\n",
    "\n",
    "# Recipient countries table\n",
    "rec_count = run_scalar(\"SELECT COUNT(*) FROM recipient_countries\")\n",
    "rec_unique = run_scalar(\"SELECT COUNT(DISTINCT recipient_country) FROM recipient_countries\")\n",
    "print(f\"\\nRecipient Countries Table:\")\n",
    "print(f\"  Total rows: {rec_count:,}\")\n",
    "print(f\"  Unique countries: {rec_unique}\")\n",
    "\n",
    "# Raw events table\n",
    "raw_events_count = run_scalar(\"SELECT COUNT(*) FROM raw_events\")\n",
    "raw_events_unique = run_scalar(\"SELECT COUNT(DISTINCT event_name) FROM raw_events\")\n",
    "print(f\"\\nRaw Events Table:\")\n",
    "print(f\"  Total rows: {raw_events_count:,}\")\n",
    "print(f\"  Unique event names: {raw_events_unique:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Event Hierarchy Analysis\n",
    "\n",
    "The event processing pipeline creates multiple levels of event aggregation:\n",
    "1. **Event Clusters** - Initial DBSCAN clustering by country/date\n",
    "2. **Canonical Events** - LLM-validated unique events\n",
    "3. **Daily Event Mentions** - Daily mentions of canonical events\n",
    "4. **Event Summaries** - Period-based summaries (daily/weekly/monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EVENT CLUSTERS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if table exists and has data\n",
    "try:\n",
    "    cluster_count = run_scalar(\"SELECT COUNT(*) FROM event_clusters\")\n",
    "    print(f\"\\nTotal Event Clusters: {cluster_count:,}\")\n",
    "    \n",
    "    if cluster_count > 0:\n",
    "        # Clusters by country\n",
    "        clusters_by_country = run_query(\"\"\"\n",
    "            SELECT \n",
    "                initiating_country,\n",
    "                COUNT(*) as cluster_count,\n",
    "                SUM(cluster_size) as total_events,\n",
    "                MIN(cluster_date) as earliest_date,\n",
    "                MAX(cluster_date) as latest_date,\n",
    "                SUM(CASE WHEN processed THEN 1 ELSE 0 END) as processed_count,\n",
    "                SUM(CASE WHEN llm_deconflicted THEN 1 ELSE 0 END) as llm_validated_count\n",
    "            FROM event_clusters\n",
    "            GROUP BY initiating_country\n",
    "            ORDER BY cluster_count DESC\n",
    "        \"\"\")\n",
    "        clusters_by_country['in_config'] = clusters_by_country['initiating_country'].isin(INFLUENCERS)\n",
    "        print(\"\\nClusters by Country:\")\n",
    "        display(clusters_by_country)\n",
    "        \n",
    "        # Clusters by month\n",
    "        clusters_by_month = run_query(\"\"\"\n",
    "            SELECT \n",
    "                DATE_TRUNC('month', cluster_date)::date as month,\n",
    "                COUNT(*) as cluster_count,\n",
    "                SUM(cluster_size) as total_events\n",
    "            FROM event_clusters\n",
    "            GROUP BY DATE_TRUNC('month', cluster_date)\n",
    "            ORDER BY month\n",
    "        \"\"\")\n",
    "        print(\"\\nClusters by Month:\")\n",
    "        display(clusters_by_month)\n",
    "except Exception as e:\n",
    "    print(f\"Event clusters table not available or empty: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CANONICAL EVENTS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    canonical_count = run_scalar(\"SELECT COUNT(*) FROM canonical_events\")\n",
    "    print(f\"\\nTotal Canonical Events: {canonical_count:,}\")\n",
    "    \n",
    "    if canonical_count > 0:\n",
    "        # Master vs child events\n",
    "        master_count = run_scalar(\"SELECT COUNT(*) FROM canonical_events WHERE master_event_id IS NULL\")\n",
    "        child_count = run_scalar(\"SELECT COUNT(*) FROM canonical_events WHERE master_event_id IS NOT NULL\")\n",
    "        print(f\"  Master events: {master_count:,}\")\n",
    "        print(f\"  Child events: {child_count:,}\")\n",
    "        \n",
    "        # By country\n",
    "        canonical_by_country = run_query(\"\"\"\n",
    "            SELECT \n",
    "                initiating_country,\n",
    "                COUNT(*) as event_count,\n",
    "                SUM(total_articles) as total_articles,\n",
    "                AVG(total_mention_days) as avg_mention_days,\n",
    "                MIN(first_mention_date) as earliest_mention,\n",
    "                MAX(last_mention_date) as latest_mention\n",
    "            FROM canonical_events\n",
    "            GROUP BY initiating_country\n",
    "            ORDER BY event_count DESC\n",
    "        \"\"\")\n",
    "        canonical_by_country['in_config'] = canonical_by_country['initiating_country'].isin(INFLUENCERS)\n",
    "        print(\"\\nCanonical Events by Country:\")\n",
    "        display(canonical_by_country)\n",
    "        \n",
    "        # Story phase distribution\n",
    "        story_phase = run_query(\"\"\"\n",
    "            SELECT \n",
    "                story_phase,\n",
    "                COUNT(*) as event_count\n",
    "            FROM canonical_events\n",
    "            GROUP BY story_phase\n",
    "            ORDER BY event_count DESC\n",
    "        \"\"\")\n",
    "        print(\"\\nStory Phase Distribution:\")\n",
    "        display(story_phase)\n",
    "        \n",
    "        # Materiality scores\n",
    "        materiality = run_query(\"\"\"\n",
    "            SELECT \n",
    "                initiating_country,\n",
    "                COUNT(*) as events_with_score,\n",
    "                AVG(material_score) as avg_score,\n",
    "                MIN(material_score) as min_score,\n",
    "                MAX(material_score) as max_score\n",
    "            FROM canonical_events\n",
    "            WHERE material_score IS NOT NULL\n",
    "            GROUP BY initiating_country\n",
    "            ORDER BY avg_score DESC\n",
    "        \"\"\")\n",
    "        print(\"\\nMateriality Scores by Country:\")\n",
    "        display(materiality)\n",
    "except Exception as e:\n",
    "    print(f\"Canonical events table not available or empty: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DAILY EVENT MENTIONS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    mention_count = run_scalar(\"SELECT COUNT(*) FROM daily_event_mentions\")\n",
    "    print(f\"\\nTotal Daily Mentions: {mention_count:,}\")\n",
    "    \n",
    "    if mention_count > 0:\n",
    "        # By country\n",
    "        mentions_by_country = run_query(\"\"\"\n",
    "            SELECT \n",
    "                initiating_country,\n",
    "                COUNT(*) as mention_count,\n",
    "                SUM(article_count) as total_articles,\n",
    "                COUNT(DISTINCT mention_date) as unique_dates,\n",
    "                MIN(mention_date) as earliest_date,\n",
    "                MAX(mention_date) as latest_date\n",
    "            FROM daily_event_mentions\n",
    "            GROUP BY initiating_country\n",
    "            ORDER BY mention_count DESC\n",
    "        \"\"\")\n",
    "        mentions_by_country['in_config'] = mentions_by_country['initiating_country'].isin(INFLUENCERS)\n",
    "        print(\"\\nDaily Mentions by Country:\")\n",
    "        display(mentions_by_country)\n",
    "        \n",
    "        # By month\n",
    "        mentions_by_month = run_query(\"\"\"\n",
    "            SELECT \n",
    "                DATE_TRUNC('month', mention_date)::date as month,\n",
    "                COUNT(*) as mention_count,\n",
    "                SUM(article_count) as total_articles\n",
    "            FROM daily_event_mentions\n",
    "            GROUP BY DATE_TRUNC('month', mention_date)\n",
    "            ORDER BY month\n",
    "        \"\"\")\n",
    "        print(\"\\nDaily Mentions by Month:\")\n",
    "        display(mentions_by_month)\n",
    "        \n",
    "        # News intensity distribution\n",
    "        intensity = run_query(\"\"\"\n",
    "            SELECT \n",
    "                news_intensity,\n",
    "                COUNT(*) as mention_count\n",
    "            FROM daily_event_mentions\n",
    "            GROUP BY news_intensity\n",
    "            ORDER BY mention_count DESC\n",
    "        \"\"\")\n",
    "        print(\"\\nNews Intensity Distribution:\")\n",
    "        display(intensity)\n",
    "except Exception as e:\n",
    "    print(f\"Daily event mentions table not available or empty: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EVENT SUMMARIES ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    summary_count = run_scalar(\"SELECT COUNT(*) FROM event_summaries\")\n",
    "    print(f\"\\nTotal Event Summaries: {summary_count:,}\")\n",
    "    \n",
    "    if summary_count > 0:\n",
    "        # By period type\n",
    "        summaries_by_type = run_query(\"\"\"\n",
    "            SELECT \n",
    "                period_type,\n",
    "                COUNT(*) as summary_count,\n",
    "                MIN(period_start) as earliest_period,\n",
    "                MAX(period_end) as latest_period\n",
    "            FROM event_summaries\n",
    "            GROUP BY period_type\n",
    "            ORDER BY summary_count DESC\n",
    "        \"\"\")\n",
    "        print(\"\\nSummaries by Period Type:\")\n",
    "        display(summaries_by_type)\n",
    "        \n",
    "        # By country\n",
    "        summaries_by_country = run_query(\"\"\"\n",
    "            SELECT \n",
    "                initiating_country,\n",
    "                COUNT(*) as summary_count,\n",
    "                SUM(total_documents_across_sources) as total_docs,\n",
    "                MIN(period_start) as earliest_period,\n",
    "                MAX(period_end) as latest_period\n",
    "            FROM event_summaries\n",
    "            GROUP BY initiating_country\n",
    "            ORDER BY summary_count DESC\n",
    "        \"\"\")\n",
    "        summaries_by_country['in_config'] = summaries_by_country['initiating_country'].isin(INFLUENCERS)\n",
    "        print(\"\\nSummaries by Country:\")\n",
    "        display(summaries_by_country)\n",
    "        \n",
    "        # Status distribution\n",
    "        status_dist = run_query(\"\"\"\n",
    "            SELECT \n",
    "                status,\n",
    "                COUNT(*) as summary_count\n",
    "            FROM event_summaries\n",
    "            GROUP BY status\n",
    "        \"\"\")\n",
    "        print(\"\\nStatus Distribution:\")\n",
    "        display(status_dist)\n",
    "except Exception as e:\n",
    "    print(f\"Event summaries table not available or empty: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Embeddings Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EMBEDDINGS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Collections\n",
    "    collections = run_query(\"\"\"\n",
    "        SELECT \n",
    "            c.name as collection_name,\n",
    "            c.uuid,\n",
    "            COUNT(e.uuid) as embedding_count\n",
    "        FROM langchain_pg_collection c\n",
    "        LEFT JOIN langchain_pg_embedding e ON c.uuid = e.collection_id\n",
    "        GROUP BY c.name, c.uuid\n",
    "        ORDER BY embedding_count DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    total_embeddings = collections['embedding_count'].sum()\n",
    "    print(f\"\\nTotal Embedding Collections: {len(collections)}\")\n",
    "    print(f\"Total Embeddings: {total_embeddings:,}\")\n",
    "    print(\"\\nCollections:\")\n",
    "    display(collections)\n",
    "except Exception as e:\n",
    "    print(f\"Embeddings tables not available: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Country-Focused Analysis (Influencers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"INFLUENCER COUNTRY DEEP DIVE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for country in INFLUENCERS:\n",
    "    print(f\"\\n{'=' * 40}\")\n",
    "    print(f\"  {country.upper()}\")\n",
    "    print(f\"{'=' * 40}\")\n",
    "    \n",
    "    # Documents\n",
    "    doc_stats = run_query(\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_docs,\n",
    "            MIN(date) as earliest_date,\n",
    "            MAX(date) as latest_date,\n",
    "            COUNT(DISTINCT date) as unique_dates\n",
    "        FROM documents\n",
    "        WHERE initiating_country = :country\n",
    "    \"\"\", {'country': country})\n",
    "    print(f\"\\n  Documents: {doc_stats['total_docs'].iloc[0]:,}\")\n",
    "    print(f\"  Date Range: {doc_stats['earliest_date'].iloc[0]} to {doc_stats['latest_date'].iloc[0]}\")\n",
    "    \n",
    "    # Top recipients\n",
    "    top_recipients = run_query(\"\"\"\n",
    "        SELECT \n",
    "            recipient_country,\n",
    "            COUNT(*) as doc_count\n",
    "        FROM documents\n",
    "        WHERE initiating_country = :country\n",
    "        AND recipient_country IS NOT NULL\n",
    "        GROUP BY recipient_country\n",
    "        ORDER BY doc_count DESC\n",
    "        LIMIT 10\n",
    "    \"\"\", {'country': country})\n",
    "    print(f\"\\n  Top 10 Recipient Countries:\")\n",
    "    for _, row in top_recipients.iterrows():\n",
    "        in_config = '(*)' if row['recipient_country'] in RECIPIENTS else ''\n",
    "        print(f\"    {row['recipient_country']}: {row['doc_count']:,} {in_config}\")\n",
    "    \n",
    "    # Categories\n",
    "    categories = run_query(\"\"\"\n",
    "        SELECT \n",
    "            category,\n",
    "            COUNT(*) as doc_count\n",
    "        FROM documents\n",
    "        WHERE initiating_country = :country\n",
    "        AND category IS NOT NULL\n",
    "        GROUP BY category\n",
    "        ORDER BY doc_count DESC\n",
    "    \"\"\", {'country': country})\n",
    "    print(f\"\\n  Categories:\")\n",
    "    for _, row in categories.iterrows():\n",
    "        print(f\"    {row['category']}: {row['doc_count']:,}\")\n",
    "    \n",
    "    # Canonical events (if available)\n",
    "    try:\n",
    "        event_stats = run_query(\"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as total_events,\n",
    "                SUM(total_articles) as total_articles,\n",
    "                AVG(material_score) as avg_materiality\n",
    "            FROM canonical_events\n",
    "            WHERE initiating_country = :country\n",
    "        \"\"\", {'country': country})\n",
    "        print(f\"\\n  Canonical Events: {event_stats['total_events'].iloc[0]:,}\")\n",
    "        print(f\"  Total Articles: {event_stats['total_articles'].iloc[0]:,}\")\n",
    "        if event_stats['avg_materiality'].iloc[0]:\n",
    "            print(f\"  Avg Materiality Score: {event_stats['avg_materiality'].iloc[0]:.2f}\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Country-Focused Analysis (Recipients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"RECIPIENT COUNTRY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Summary for all config recipients\n",
    "recipient_summary = []\n",
    "\n",
    "for country in RECIPIENTS:\n",
    "    stats = run_query(\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_docs,\n",
    "            COUNT(DISTINCT initiating_country) as unique_influencers,\n",
    "            MIN(date) as earliest_date,\n",
    "            MAX(date) as latest_date\n",
    "        FROM documents\n",
    "        WHERE recipient_country = :country\n",
    "    \"\"\", {'country': country})\n",
    "    \n",
    "    recipient_summary.append({\n",
    "        'recipient_country': country,\n",
    "        'total_docs': stats['total_docs'].iloc[0],\n",
    "        'unique_influencers': stats['unique_influencers'].iloc[0],\n",
    "        'earliest_date': stats['earliest_date'].iloc[0],\n",
    "        'latest_date': stats['latest_date'].iloc[0]\n",
    "    })\n",
    "\n",
    "recipient_df = pd.DataFrame(recipient_summary)\n",
    "recipient_df = recipient_df.sort_values('total_docs', ascending=False)\n",
    "print(\"\\nRecipient Countries Summary:\")\n",
    "recipient_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Influencer activity in top recipient countries\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INFLUENCER ACTIVITY BY RECIPIENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "top_recipients = recipient_df.head(10)['recipient_country'].tolist()\n",
    "\n",
    "for recipient in top_recipients:\n",
    "    print(f\"\\n  {recipient}:\")\n",
    "    influencer_activity = run_query(\"\"\"\n",
    "        SELECT \n",
    "            initiating_country,\n",
    "            COUNT(*) as doc_count\n",
    "        FROM documents\n",
    "        WHERE recipient_country = :recipient\n",
    "        AND initiating_country IN :influencers\n",
    "        GROUP BY initiating_country\n",
    "        ORDER BY doc_count DESC\n",
    "    \"\"\", {'recipient': recipient, 'influencers': tuple(INFLUENCERS)})\n",
    "    \n",
    "    for _, row in influencer_activity.iterrows():\n",
    "        print(f\"    {row['initiating_country']}: {row['doc_count']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Bilateral Relationship Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BILATERAL RELATIONSHIP SUMMARIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    bilateral_count = run_scalar(\"SELECT COUNT(*) FROM bilateral_relationship_summaries\")\n",
    "    print(f\"\\nTotal Bilateral Summaries: {bilateral_count:,}\")\n",
    "    \n",
    "    if bilateral_count > 0:\n",
    "        bilateral_summaries = run_query(\"\"\"\n",
    "            SELECT \n",
    "                initiating_country,\n",
    "                recipient_country,\n",
    "                total_documents,\n",
    "                total_daily_events,\n",
    "                material_score_avg,\n",
    "                first_interaction_date,\n",
    "                last_interaction_date\n",
    "            FROM bilateral_relationship_summaries\n",
    "            WHERE is_deleted = false\n",
    "            ORDER BY total_documents DESC\n",
    "            LIMIT 20\n",
    "        \"\"\")\n",
    "        print(\"\\nTop 20 Bilateral Relationships by Document Count:\")\n",
    "        display(bilateral_summaries)\n",
    "except Exception as e:\n",
    "    print(f\"Bilateral summaries table not available: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DATA QUALITY CHECKS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Null checks for documents\n",
    "null_checks = run_query(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_docs,\n",
    "        SUM(CASE WHEN date IS NULL THEN 1 ELSE 0 END) as null_dates,\n",
    "        SUM(CASE WHEN initiating_country IS NULL THEN 1 ELSE 0 END) as null_init_country,\n",
    "        SUM(CASE WHEN recipient_country IS NULL THEN 1 ELSE 0 END) as null_rec_country,\n",
    "        SUM(CASE WHEN category IS NULL THEN 1 ELSE 0 END) as null_category,\n",
    "        SUM(CASE WHEN salience_bool IS NULL THEN 1 ELSE 0 END) as null_salience\n",
    "    FROM documents\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nNull Value Analysis (Documents):\")\n",
    "total = null_checks['total_docs'].iloc[0]\n",
    "print(f\"  Total documents: {total:,}\")\n",
    "print(f\"  Null dates: {null_checks['null_dates'].iloc[0]:,} ({null_checks['null_dates'].iloc[0]/total*100:.1f}%)\")\n",
    "print(f\"  Null initiating_country: {null_checks['null_init_country'].iloc[0]:,} ({null_checks['null_init_country'].iloc[0]/total*100:.1f}%)\")\n",
    "print(f\"  Null recipient_country: {null_checks['null_rec_country'].iloc[0]:,} ({null_checks['null_rec_country'].iloc[0]/total*100:.1f}%)\")\n",
    "print(f\"  Null category: {null_checks['null_category'].iloc[0]:,} ({null_checks['null_category'].iloc[0]/total*100:.1f}%)\")\n",
    "print(f\"  Null salience_bool: {null_checks['null_salience'].iloc[0]:,} ({null_checks['null_salience'].iloc[0]/total*100:.1f}%)\")\n",
    "\n",
    "# Orphan checks\n",
    "print(\"\\nOrphan Record Checks:\")\n",
    "try:\n",
    "    orphan_categories = run_scalar(\"\"\"\n",
    "        SELECT COUNT(*) FROM categories c\n",
    "        WHERE NOT EXISTS (SELECT 1 FROM documents d WHERE d.doc_id = c.doc_id)\n",
    "    \"\"\")\n",
    "    print(f\"  Orphan categories: {orphan_categories:,}\")\n",
    "except:\n",
    "    print(\"  Orphan categories: N/A\")\n",
    "\n",
    "try:\n",
    "    orphan_mentions = run_scalar(\"\"\"\n",
    "        SELECT COUNT(*) FROM daily_event_mentions m\n",
    "        WHERE NOT EXISTS (SELECT 1 FROM canonical_events e WHERE e.id = m.canonical_event_id)\n",
    "    \"\"\")\n",
    "    print(f\"  Orphan daily mentions: {orphan_mentions:,}\")\n",
    "except:\n",
    "    print(\"  Orphan daily mentions: N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXECUTIVE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "summary = {\n",
    "    'metric': [],\n",
    "    'value': []\n",
    "}\n",
    "\n",
    "# Documents\n",
    "summary['metric'].append('Total Documents')\n",
    "summary['value'].append(f\"{run_scalar('SELECT COUNT(*) FROM documents'):,}\")\n",
    "\n",
    "# Date range\n",
    "date_info = run_query(\"SELECT MIN(date), MAX(date) FROM documents WHERE date IS NOT NULL\")\n",
    "summary['metric'].append('Date Range')\n",
    "summary['value'].append(f\"{date_info.iloc[0, 0]} to {date_info.iloc[0, 1]}\")\n",
    "\n",
    "# Influencer coverage\n",
    "influencer_docs = run_scalar(f\"\"\"\n",
    "    SELECT COUNT(*) FROM documents \n",
    "    WHERE initiating_country IN {tuple(INFLUENCERS)}\n",
    "\"\"\")\n",
    "summary['metric'].append('Documents from Config Influencers')\n",
    "summary['value'].append(f\"{influencer_docs:,}\")\n",
    "\n",
    "# Recipient coverage\n",
    "recipient_docs = run_scalar(f\"\"\"\n",
    "    SELECT COUNT(*) FROM documents \n",
    "    WHERE recipient_country IN {tuple(RECIPIENTS)}\n",
    "\"\"\")\n",
    "summary['metric'].append('Documents to Config Recipients')\n",
    "summary['value'].append(f\"{recipient_docs:,}\")\n",
    "\n",
    "# Events\n",
    "try:\n",
    "    summary['metric'].append('Canonical Events')\n",
    "    summary['value'].append(f\"{run_scalar('SELECT COUNT(*) FROM canonical_events'):,}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    summary['metric'].append('Event Clusters')\n",
    "    summary['value'].append(f\"{run_scalar('SELECT COUNT(*) FROM event_clusters'):,}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    summary['metric'].append('Daily Event Mentions')\n",
    "    summary['value'].append(f\"{run_scalar('SELECT COUNT(*) FROM daily_event_mentions'):,}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    summary['metric'].append('Event Summaries')\n",
    "    summary['value'].append(f\"{run_scalar('SELECT COUNT(*) FROM event_summaries'):,}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Embeddings\n",
    "try:\n",
    "    summary['metric'].append('Total Embeddings')\n",
    "    summary['value'].append(f\"{run_scalar('SELECT COUNT(*) FROM langchain_pg_embedding'):,}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(\"\\n\")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"AUDIT COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nGenerated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
