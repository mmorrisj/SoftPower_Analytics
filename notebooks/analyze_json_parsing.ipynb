{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load the sample JSON file\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Load the sample JSON file\n",
    "json_file = r'C:\\Users\\mmorr\\Desktop\\Apps\\SP_Streamlit\\data\\results-2025-10-08-2025-10-14.json'\n",
    "\n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Total documents in file: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze event-name field presence and values\n",
    "results = []\n",
    "\n",
    "for doc in data[:100]:  # Sample first 100 docs\n",
    "    doc_id = doc.get('id', 'unknown')\n",
    "    \n",
    "    # Check if doc has proper structure\n",
    "    if 'auto' not in doc:\n",
    "        results.append({\n",
    "            'doc_id': doc_id,\n",
    "            'has_auto': False,\n",
    "            'has_gai': False,\n",
    "            'gai_count': 0,\n",
    "            'has_event_name_field': False,\n",
    "            'event_name_value': None\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    gai = doc['auto'].get('gai', [])\n",
    "    if len(gai) < 2:\n",
    "        results.append({\n",
    "            'doc_id': doc_id,\n",
    "            'has_auto': True,\n",
    "            'has_gai': True,\n",
    "            'gai_count': len(gai),\n",
    "            'has_event_name_field': False,\n",
    "            'event_name_value': None\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    # Get the second gai entry (index 1)\n",
    "    gai_values = gai[1].get('value', [])\n",
    "    \n",
    "    # Look for event-name field\n",
    "    event_name_field = None\n",
    "    for item in gai_values:\n",
    "        if item.get('type') == 'event-name':\n",
    "            event_name_field = item.get('value')\n",
    "            break\n",
    "    \n",
    "    results.append({\n",
    "        'doc_id': doc_id,\n",
    "        'has_auto': True,\n",
    "        'has_gai': True,\n",
    "        'gai_count': len(gai),\n",
    "        'has_event_name_field': event_name_field is not None,\n",
    "        'event_name_value': event_name_field\n",
    "    })\n",
    "\n",
    "df_analysis = pd.DataFrame(results)\n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n=== SUMMARY STATISTICS (first 100 docs) ===\")\n",
    "print(f\"Docs with 'auto' field: {df_analysis['has_auto'].sum()}\")\n",
    "print(f\"Docs with 'gai' field: {df_analysis['has_gai'].sum()}\")\n",
    "print(f\"Docs with event-name field present: {df_analysis['has_event_name_field'].sum()}\")\n",
    "print(f\"Docs with non-empty event-name value: {df_analysis['event_name_value'].notna().sum()}\")\n",
    "\n",
    "# Count empty/None event names\n",
    "empty_event_names = df_analysis[\n",
    "    df_analysis['has_event_name_field'] & \n",
    "    (df_analysis['event_name_value'].isna() | (df_analysis['event_name_value'] == ''))\n",
    "]\n",
    "print(f\"\\nDocs with event-name field but EMPTY/NONE value: {len(empty_event_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at actual event-name values\n",
    "print(\"\\n=== SAMPLE EVENT-NAME VALUES ===\")\n",
    "sample_events = df_analysis[df_analysis['event_name_value'].notna()]['event_name_value'].head(20)\n",
    "for i, event in enumerate(sample_events, 1):\n",
    "    print(f\"{i}. {event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the normalization logic from dsr.py\n",
    "def normalize_value(response_value):\n",
    "    \"\"\"Test the normalization logic from dsr.py lines 138-142\"\"\"\n",
    "    normalized_value = (\n",
    "        response_value\n",
    "        if response_value and response_value.strip().lower() not in ['n/a', 'na', 'none', 'null', '']\n",
    "        else None\n",
    "    )\n",
    "    return normalized_value\n",
    "\n",
    "# Test on sample event names\n",
    "print(\"\\n=== TESTING NORMALIZATION LOGIC ===\")\n",
    "test_values = df_analysis['event_name_value'].dropna().head(10).tolist()\n",
    "for val in test_values:\n",
    "    normalized = normalize_value(val)\n",
    "    print(f\"Original: '{val}' -> Normalized: '{normalized}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for documents where event-name might be missing but projects exists\n",
    "print(\"\\n=== CHECKING FALLBACK TO PROJECTS ===\")\n",
    "\n",
    "fallback_cases = []\n",
    "for doc in data[:100]:\n",
    "    if 'auto' not in doc or len(doc['auto'].get('gai', [])) < 2:\n",
    "        continue\n",
    "    \n",
    "    gai_values = doc['auto']['gai'][1].get('value', [])\n",
    "    \n",
    "    event_name = None\n",
    "    projects = None\n",
    "    \n",
    "    for item in gai_values:\n",
    "        if item.get('type') == 'event-name':\n",
    "            event_name = item.get('value')\n",
    "        elif item.get('type') == 'projects':\n",
    "            projects = item.get('value')\n",
    "    \n",
    "    # Case where event-name is empty but projects exists\n",
    "    if (not event_name or event_name.strip().lower() in ['n/a', 'na', 'none', 'null', '']) and projects:\n",
    "        fallback_cases.append({\n",
    "            'doc_id': doc['id'],\n",
    "            'event_name': event_name,\n",
    "            'projects': projects\n",
    "        })\n",
    "\n",
    "print(f\"Found {len(fallback_cases)} cases where projects could be used as fallback\")\n",
    "if fallback_cases:\n",
    "    for case in fallback_cases[:10]:\n",
    "        print(f\"  Doc {case['doc_id']}: event-name='{case['event_name']}', projects='{case['projects']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full analysis on entire file\n",
    "print(\"\\n=== ANALYZING ENTIRE FILE ===\")\n",
    "\n",
    "total_docs = len(data)\n",
    "docs_with_event_field = 0\n",
    "docs_with_empty_event = 0\n",
    "docs_with_valid_event = 0\n",
    "docs_missing_auto = 0\n",
    "\n",
    "for doc in data:\n",
    "    if 'auto' not in doc:\n",
    "        docs_missing_auto += 1\n",
    "        continue\n",
    "    \n",
    "    gai = doc['auto'].get('gai', [])\n",
    "    if len(gai) < 2:\n",
    "        continue\n",
    "    \n",
    "    gai_values = gai[1].get('value', [])\n",
    "    \n",
    "    for item in gai_values:\n",
    "        if item.get('type') == 'event-name':\n",
    "            docs_with_event_field += 1\n",
    "            value = item.get('value', '')\n",
    "            \n",
    "            # Check if value is empty or invalid\n",
    "            if not value or value.strip().lower() in ['n/a', 'na', 'none', 'null', '']:\n",
    "                docs_with_empty_event += 1\n",
    "            else:\n",
    "                docs_with_valid_event += 1\n",
    "            break\n",
    "\n",
    "print(f\"Total documents: {total_docs}\")\n",
    "print(f\"Documents missing 'auto' field: {docs_missing_auto}\")\n",
    "print(f\"Documents with 'event-name' field: {docs_with_event_field}\")\n",
    "print(f\"Documents with VALID event-name: {docs_with_valid_event}\")\n",
    "print(f\"Documents with EMPTY/INVALID event-name: {docs_with_empty_event}\")\n",
    "print(f\"\\nPercentage with valid event-name: {docs_with_valid_event / total_docs * 100:.1f}%\")\n",
    "print(f\"Percentage with empty event-name: {docs_with_empty_event / total_docs * 100:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
